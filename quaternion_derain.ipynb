{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "quaternion_derain.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/qderain/blob/main/quaternion_derain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7iTEHLw-LJh",
        "outputId": "2d714486-6a4b-402d-ed9a-6db72bedabc0"
      },
      "source": [
        "!pip install git+https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks.git\n",
            "  Cloning https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks.git to /tmp/pip-req-build-_nuo1ji6\n",
            "  Running command git clone -q https://github.com/Orkis-Research/Pytorch-Quaternion-Neural-Networks.git /tmp/pip-req-build-_nuo1ji6\n",
            "Building wheels for collected packages: Pytorch-QNN\n",
            "  Building wheel for Pytorch-QNN (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pytorch-QNN: filename=Pytorch_QNN-1-py3-none-any.whl size=21517 sha256=a8447e13b21d841ae7817b52cbf1aa60759b53e50243cc39a1975b9051752974\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2qg4mggu/wheels/28/96/bc/2d440ce957d6b5ce8d0345b758b7828d07fae2c5a9f3fae8c7\n",
            "Successfully built Pytorch-QNN\n",
            "Installing collected packages: Pytorch-QNN\n",
            "Successfully installed Pytorch-QNN-1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKaSMHLCGy8x",
        "outputId": "561d5eb0-ae74-4ed6-c186-2797685338f3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jan 13 09:15:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61n1iDXE_lak"
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "import cv2\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from scipy import signal\n",
        "from torchvision.utils import make_grid\n",
        "import numpy.random as random\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "from core_qnn.quaternion_layers import QuaternionTransposeConv\n",
        "from core_qnn.quaternion_layers import QuaternionConv\n",
        "from core_qnn.quaternion_ops import check_input\n",
        "from core_qnn.quaternion_ops import get_r, get_i, get_j, get_k"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyHJyTb29fby",
        "outputId": "83938889-d8bc-41bf-e2a2-7cb82ac5d6e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaBMsBilBGdP"
      },
      "source": [
        "!cp /content/drive/MyDrive/derain/rain200H.zip .\n",
        "!unzip -q rain200H.zip"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls rain200H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BXM-m5UuzF3",
        "outputId": "4253f16a-819b-445a-f8c2-efb26b8c004b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f45Irh1x_-0s"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK0kFuR__sQs"
      },
      "source": [
        "IMG_EXTENSIONS = [\n",
        "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
        "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
        "]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0FK4KkE_sS0"
      },
      "source": [
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5vIZRvi_sVc"
      },
      "source": [
        "def make_dataset(dir):\n",
        "    images = []\n",
        "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
        "\n",
        "    for root, _, fnames in sorted(os.walk(dir)):\n",
        "        for fname in fnames:\n",
        "            if is_image_file(fname):\n",
        "                path = os.path.join(root, fname)\n",
        "                images.append(path)\n",
        "\n",
        "    return images"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYRGhIv5_sXq"
      },
      "source": [
        "def edge_compute(x):\n",
        "    x_diffx = torch.abs(x[:,:,1:] - x[:,:,:-1])\n",
        "    x_diffy = torch.abs(x[:,1:,:] - x[:,:-1,:])\n",
        "\n",
        "    y = x.new(x.size())\n",
        "    y.fill_(0)\n",
        "    y[:,:,1:] += x_diffx\n",
        "    y[:,:,:-1] += x_diffx\n",
        "    y[:,1:,:] += x_diffy\n",
        "    y[:,:-1,:] += x_diffy\n",
        "    y = torch.sum(y,0,keepdim=True)/3\n",
        "    y /= 4\n",
        "    return y"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTjmsAdO_saf"
      },
      "source": [
        "def batch_edge_compute(x):\n",
        "    x_diffx = torch.abs(x[:,:,:,1:] - x[:,:,:,:-1])\n",
        "    x_diffy = torch.abs(x[:,:,1:,:] - x[:,:,:-1,:])\n",
        "\n",
        "    y = x.new(x.size())\n",
        "    y.fill_(0)\n",
        "    y[:,:,:,1:] += x_diffx\n",
        "    y[:,:,:,:-1] += x_diffx\n",
        "    y[:,:,1:,:] += x_diffy\n",
        "    y[:,:,:-1,:] += x_diffy\n",
        "    y = torch.sum(y,1,keepdim=True)/3\n",
        "    y /= 4\n",
        "    return y"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kntHEBEJ_sdK"
      },
      "source": [
        "# Converts a Tensor into an image array (numpy)\n",
        "# |imtype|: the desired type of the converted numpy array\n",
        "def tensor2im(input_image, imtype=np.uint8):\n",
        "    if isinstance(input_image, torch.Tensor):\n",
        "        image_tensor = input_image.data\n",
        "    else:\n",
        "        return input_image\n",
        "    image_numpy = image_tensor[0].cpu().float().numpy()\n",
        "    if image_numpy.shape[0] == 1:\n",
        "        image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "    image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
        "    image_numpy = image_numpy.clip(0, 255)\n",
        "    return image_numpy.astype(imtype)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6bTUFbbAPIM"
      },
      "source": [
        "def tensor2imgrid(input_image):\n",
        "    im_grid = make_grid(input_image[:4, ...], nrow=2, normalize=True, range=(-128, 128))\n",
        "    return im_grid\n",
        "    # ndarr = im_grid.mul(255).clamp(0, 255).byte().permute(1, 2, 0).cpu().numpy()\n",
        "    # im = Image.fromarray(ndarr)\n",
        "    # return im"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hxIDAhPARGR"
      },
      "source": [
        "def diagnose_network(net, name='network'):\n",
        "    mean = 0.0\n",
        "    count = 0\n",
        "    for param in net.parameters():\n",
        "        if param.grad is not None:\n",
        "            mean += torch.mean(torch.abs(param.grad.data))\n",
        "            count += 1\n",
        "    if count > 0:\n",
        "        mean = mean / count\n",
        "    print(name)\n",
        "    print(mean)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzxNa4eRARIe"
      },
      "source": [
        "def save_image(image_numpy, image_path):\n",
        "    image_pil = Image.fromarray(image_numpy)\n",
        "    image_pil.save(image_path)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1WntY9tARKc"
      },
      "source": [
        "def print_numpy(x, val=True, shp=False):\n",
        "    x = x.astype(np.float64)\n",
        "    if shp:\n",
        "        print('shape,', x.shape)\n",
        "    if val:\n",
        "        x = x.flatten()\n",
        "        print('mean = %3.3f, min = %3.3f, max = %3.3f, median = %3.3f, std=%3.3f' % (\n",
        "            np.mean(x), np.min(x), np.max(x), np.median(x), np.std(x)))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qxpi18nTAPKd"
      },
      "source": [
        "def mkdirs(paths):\n",
        "    if isinstance(paths, list) and not isinstance(paths, str):\n",
        "        for path in paths:\n",
        "            mkdir(path)\n",
        "    else:\n",
        "        mkdir(paths)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9VT_UpUAPNR"
      },
      "source": [
        "def mkdir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubYy6GYiAPPT"
      },
      "source": [
        "def fspecial_gauss(size, sigma):\n",
        "    \"\"\"Function to mimic the 'fspecial' gaussian MATLAB function\n",
        "    \"\"\"\n",
        "    x, y = np.mgrid[-size // 2 + 1:size // 2 + 1, -size // 2 + 1:size // 2 + 1]\n",
        "    g = np.exp(-((x ** 2 + y ** 2) / (2.0 * sigma ** 2)))\n",
        "    return g / g.sum()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBzm_GbM_sfv"
      },
      "source": [
        "def filter2(x, kernel, mode='same'):\n",
        "    return signal.convolve2d(x, np.rot90(kernel, 2), mode=mode)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6rFv5jZAdzP"
      },
      "source": [
        "def ssim(img1, img2, cs_map=False):\n",
        "    \"\"\"Return the Structural Similarity Map corresponding to input images img1\n",
        "    and img2 (images are assumed to be uint8)\n",
        "\n",
        "    This function attempts to mimic precisely the functionality of ssim.m a\n",
        "    MATLAB provided by the author's of SSIM\n",
        "    https://ece.uwaterloo.ca/~z70wang/research/ssim/ssim_index.m\n",
        "    \"\"\"\n",
        "    img1 = img1.astype(np.float64)\n",
        "    img2 = img2.astype(np.float64)\n",
        "    size = 11\n",
        "    sigma = 1.5\n",
        "    window = fspecial_gauss(size, sigma)\n",
        "    K1 = 0.01\n",
        "    K2 = 0.03\n",
        "    L = 255  # bitdepth of image\n",
        "    C1 = (K1 * L) ** 2\n",
        "    C2 = (K2 * L) ** 2\n",
        "    mu1 = filter2(img1, window, mode='valid')\n",
        "    mu2 = filter2(img2, window, mode='valid')\n",
        "    mu1_sq = mu1 * mu1\n",
        "    mu2_sq = mu2 * mu2\n",
        "    mu1_mu2 = mu1 * mu2\n",
        "    sigma1_sq = filter2(img1 * img1, window, mode='valid') - mu1_sq\n",
        "    sigma2_sq = filter2(img2 * img2, window, mode='valid') - mu2_sq\n",
        "    sigma12 = filter2(img1 * img2, window, mode='valid') - mu1_mu2\n",
        "    if cs_map:\n",
        "        return np.mean(np.mean((((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
        "                                                             (sigma1_sq + sigma2_sq + C2)),\n",
        "                (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2))))\n",
        "    else:\n",
        "        return np.mean(np.mean(((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) *\n",
        "                                                            (sigma1_sq + sigma2_sq + C2))))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt-9wBbYAd1n"
      },
      "source": [
        "class MovingAvg(object):\n",
        "    def __init__(self, pool_size=100):\n",
        "        from queue import Queue\n",
        "        self.pool = Queue(maxsize=pool_size)\n",
        "        self.sum = 0\n",
        "        self.curr_pool_size = 0\n",
        "        self.pool_size = pool_size\n",
        "\n",
        "    def set_curr_val(self, val):\n",
        "        if not self.pool.full():\n",
        "            self.curr_pool_size += 1\n",
        "            self.pool.put_nowait(val)\n",
        "        else:\n",
        "            last_first_val = self.pool.get_nowait()\n",
        "            self.pool.put_nowait(val)\n",
        "            self.sum -= last_first_val\n",
        "\n",
        "        self.sum += val\n",
        "        return self.sum / self.curr_pool_size\n",
        "\n",
        "    def reset(self):\n",
        "        from queue import Queue\n",
        "        self.pool = Queue(maxsize=self.pool_size)\n",
        "        self.sum = 0\n",
        "        self.curr_pool_size = 0"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwVJR_-VAmVz"
      },
      "source": [
        "# Folder loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzoURrapAd3z"
      },
      "source": [
        "class FolderLoader(object):\n",
        "    def __init__(self, fold_path):\n",
        "        super(FolderLoader, self).__init__()\n",
        "        self.fold_path = fold_path\n",
        "        self.img_paths = make_dataset(self.fold_path)\n",
        "        self.img_names = [os.path.basename(x) for x in self.img_paths]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.img_paths[index])#.convert('RGB')\n",
        "        return self.img_names[index], img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhteEF8wBR6_"
      },
      "source": [
        "def pil_loader(img_path):\n",
        "    return Image.open(img_path).convert(\"RGB\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfuYcN_OBSFh"
      },
      "source": [
        "class ImagePairPrefixFolder(Dataset):\n",
        "    def __init__(self, input_folder, gt_folder, max_img_size=0, size_unit=1, force_rgb=False):\n",
        "        super(ImagePairPrefixFolder, self).__init__()\n",
        "\n",
        "        self.gt_loader = FolderLoader(gt_folder)\n",
        "        # build the map from image name to index\n",
        "        self.gt_map = dict()\n",
        "        for idx, img_name in enumerate(self.gt_loader.img_names):\n",
        "            self.gt_map[os.path.splitext(img_name)[0].split('_')[0]] = idx\n",
        "\n",
        "        self.input_loader = FolderLoader(input_folder)\n",
        "        assert all([os.path.splitext(x)[0].split('_')[0] in self.gt_map for x in self.input_loader.img_names]), \\\n",
        "                'cannot find corresponding gt names'\n",
        "\n",
        "\n",
        "        self.input_folder = input_folder\n",
        "        self.gt_folder = gt_folder\n",
        "        self.max_img_size = max_img_size\n",
        "        self.size_unit = size_unit\n",
        "        self.force_rgb = force_rgb\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        input_name, input_img = self.input_loader[index]\n",
        "        input_basename = os.path.splitext(input_name)[0].split('_')[0]\n",
        "        gt_idx = self.gt_map[input_basename]\n",
        "\n",
        "        gt_name, gt_img = self.gt_loader[gt_idx]\n",
        "        if self.force_rgb:\n",
        "            input_img = input_img.convert('RGB')\n",
        "            gt_img = gt_img.convert('RGB')\n",
        "        im_w, im_h = input_img.size\n",
        "        gt_w, gt_h = gt_img.size\n",
        "\n",
        "        if (im_w != gt_w) or (im_h != gt_h):\n",
        "          print(input_name)\n",
        "          print(gt_name)\n",
        "\n",
        "        assert im_w==gt_w and im_h==gt_h, 'input image and gt image size not match'\n",
        "\n",
        "        im_w, im_h = input_img.size\n",
        "        if 0 < self.max_img_size < max(im_w, im_h):\n",
        "            if im_w < im_h:\n",
        "                out_h = int(self.max_img_size) // self.size_unit * self.size_unit\n",
        "                out_w = int(im_w / im_h * out_h) // self.size_unit * self.size_unit\n",
        "            else:\n",
        "                out_w = int(self.max_img_size) // self.size_unit * self.size_unit\n",
        "                out_h = int(im_h / im_w * out_w) // self.size_unit * self.size_unit\n",
        "        else:\n",
        "            out_w = im_w // self.size_unit * self.size_unit\n",
        "            out_h = im_h // self.size_unit * self.size_unit\n",
        "\n",
        "        if im_w != out_w or im_h != out_h:\n",
        "            input_img = input_img.resize((out_w, out_h), Image.BILINEAR)\n",
        "            gt_img = gt_img.resize((out_w, out_h), Image.BILINEAR)\n",
        "\n",
        "        im_w, im_h = input_img.size\n",
        "\n",
        "        \n",
        "        #input_img = np.array(input_img).astype('float')\n",
        "        #input_img = np.array(input_img)\n",
        "\n",
        "        input_img = np.array(input_img)\n",
        "        gray = cv2.cvtColor(input_img, cv2.COLOR_RGB2GRAY)\n",
        "        #gray = cv2.imread(os.path.join('ds/train_general/trans/', input_name.replace('.jpg', '.png')), 0)\n",
        "        #gray = cv2.resize(gray, (out_w, out_h))\n",
        "        input_img = np.dstack([gray[:, :, np.newaxis], input_img])\n",
        "        input_img = input_img.astype('float')\n",
        "\n",
        "\n",
        "        gt_img = np.array(gt_img)\n",
        "        gray = cv2.cvtColor(gt_img, cv2.COLOR_RGB2GRAY)\n",
        "        gt_img = np.dstack([gray[:, :, np.newaxis], gt_img])\n",
        "        gt_img = gt_img.astype('float')\n",
        "        if len(input_img.shape) == 2:\n",
        "            input_img = input_img[:, :, np.newaxis]\n",
        "        if len(gt_img.shape) == 2:\n",
        "            gt_img = gt_img[:, :, np.newaxis]\n",
        "\n",
        "        input_img = input_img\n",
        "        gt_img = gt_img\n",
        "        return {'input_img': input_img, 'gt_img': gt_img,  'input_h': im_h, \"input_w\": im_w}\n",
        "\n",
        "    def get_input_info(self, index):\n",
        "        image_name = os.path.splitext(self.input_loader.img_names[index])[0]\n",
        "        return self.input_loader, image_name\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.input_loader)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cji84_O5BZX0"
      },
      "source": [
        "def var_custom_collate(batch):\n",
        "    min_h, min_w = 10000, 10000\n",
        "    for item in batch:\n",
        "        min_h = min(min_h, item['input_h'])\n",
        "        min_w = min(min_w, item['input_w'])\n",
        "    inc = 1 if len(batch[0]['input_img'].shape)==2 else batch[0]['input_img'].shape[2]\n",
        "    batch_input_images = torch.Tensor(len(batch), 4, min_h, min_w)\n",
        "    batch_gt_images = torch.Tensor(len(batch), 4, min_h, min_w)\n",
        "\n",
        "    for idx, item in enumerate(batch):\n",
        "        off_y = 0 if item['input_h']==min_h else random.randint(0, item['input_h'] - min_h)\n",
        "        off_x = 0 if item['input_w']==min_w else random.randint(0, item['input_w'] - min_w)\n",
        "        crop_input_img = item['input_img'][off_y:off_y + min_h, off_x:off_x + min_w, :]\n",
        "        crop_gt_img = item['gt_img'][off_y:off_y + min_h, off_x:off_x + min_w, :]\n",
        "        batch_input_images[idx] = torch.from_numpy(crop_input_img.transpose((2, 0, 1))) - 128\n",
        "        batch_gt_images[idx] = torch.from_numpy(crop_gt_img.transpose((2, 0, 1)))\n",
        "\n",
        "\n",
        "    batch_input_edges = batch_edge_compute(batch_input_images) - 128\n",
        "    return batch_input_images, batch_input_edges,  batch_gt_images"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqgIOJoqArjA"
      },
      "source": [
        "# Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdjHV5g2AqnB"
      },
      "source": [
        "class ShareSepConv(nn.Module):\n",
        "    def __init__(self, kernel_size):\n",
        "        super(ShareSepConv, self).__init__()\n",
        "        assert kernel_size % 2 == 1, 'kernel size should be odd'\n",
        "        self.padding = (kernel_size - 1)//2\n",
        "        weight_tensor = torch.zeros(1, 1, kernel_size, kernel_size)\n",
        "        weight_tensor[0, 0, (kernel_size-1)//2, (kernel_size-1)//2] = 1\n",
        "        self.weight = nn.Parameter(weight_tensor)\n",
        "        self.kernel_size = kernel_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        inc = x.size(1)\n",
        "        expand_weight = self.weight.expand(inc, 1, self.kernel_size, self.kernel_size).contiguous()\n",
        "        return F.conv2d(x, expand_weight,\n",
        "                        None, 1, self.padding, 1, inc)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cGba02BysY8"
      },
      "source": [
        "class QuaternionInstanceNorm2d(nn.Module):\n",
        "    def __init__(self, num_features, gamma_init=1., beta_param=True, training=True):\n",
        "        super(QuaternionInstanceNorm2d, self).__init__()\n",
        "        self.num_features = num_features // 4\n",
        "        self.gamma_init = gamma_init\n",
        "        self.beta_param = beta_param\n",
        "        self.gamma = nn.Parameter(torch.full([1, self.num_features, 1, 1], self.gamma_init))\n",
        "        self.beta = nn.Parameter(torch.zeros(1, self.num_features * 4, 1, 1), requires_grad=self.beta_param)\n",
        "        self.training = training\n",
        "        self.eps = torch.tensor(1e-5)\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.gamma = nn.Parameter(torch.full([1, self.num_features, 1, 1], self.gamma_init))\n",
        "        self.beta = nn.Parameter(torch.zeros(1, self.num_features * 4, 1, 1), requires_grad=self.beta_param)\n",
        "\n",
        "    def forward(self, input):\n",
        "        quat_components = torch.chunk(input, 4, dim=1)\n",
        "        r, i, j, k = quat_components[0], quat_components[1], quat_components[2], quat_components[3]\n",
        "        delta_r, delta_i, delta_j, delta_k = r - torch.mean(r, axis=[1, 2, 3], keepdim=True), i - torch.mean(i, axis=[1, 2, 3], keepdim=True), j - torch.mean(j, axis=[1, 2, 3], keepdim=True), k - torch.mean(k, axis=[1, 2, 3], keepdim=True)\n",
        "        quat_variance = torch.mean((delta_r**2 + delta_i**2 + delta_j**2 + delta_k**2))\n",
        "        denominator = torch.sqrt(quat_variance + self.eps)\n",
        "\n",
        "        # Normalize\n",
        "        r_normalized = delta_r / denominator\n",
        "        i_normalized = delta_i / denominator\n",
        "        j_normalized = delta_j / denominator\n",
        "        k_normalized = delta_k / denominator\n",
        "\n",
        "        beta_components = torch.chunk(self.beta, 4, dim=1)\n",
        "\n",
        "        # Multiply gamma (stretch scale) and add beta (shift scale)\n",
        "        new_r = (self.gamma * r_normalized) + beta_components[0]\n",
        "        new_i = (self.gamma * i_normalized) + beta_components[1]\n",
        "        new_j = (self.gamma * j_normalized) + beta_components[2]\n",
        "        new_k = (self.gamma * k_normalized) + beta_components[3]\n",
        "\n",
        "        new_input = torch.cat((new_r, new_i, new_j, new_k), dim=1)\n",
        "\n",
        "        return new_input\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(' \\\n",
        "               + 'num_features=' + str(self.num_features) \\\n",
        "               + ', gamma=' + str(self.gamma) \\\n",
        "               + ', beta=' + str(self.beta) \\\n",
        "               + ', eps=' + str(self.eps) + ')'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "duT8AB12Aqrq"
      },
      "source": [
        "class SmoothDilatedResidualBlock(nn.Module):\n",
        "    def __init__(self, channel_num, dilation=1, group=1):\n",
        "        super(SmoothDilatedResidualBlock, self).__init__()\n",
        "        self.pre_conv1 = ShareSepConv(dilation*2-1)\n",
        "        self.conv1 = QuaternionConv(channel_num, channel_num, 3, 1, padding=dilation, dilatation=dilation, groups=group, bias=False)\n",
        "        self.norm1 = QuaternionInstanceNorm2d(channel_num)\n",
        "        self.pre_conv2 = ShareSepConv(dilation*2-1)\n",
        "        self.conv2 = QuaternionConv(channel_num, channel_num, 3, 1, padding=dilation, dilatation=dilation, groups=group, bias=False)\n",
        "        self.norm2 = QuaternionInstanceNorm2d(channel_num)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = F.relu(self.norm1(self.conv1(self.pre_conv1(x))))\n",
        "        y = self.norm2(self.conv2(self.pre_conv2(y)))\n",
        "        return F.relu(x+y)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkFC-x0PAqui"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channel_num, dilation=1, group=1):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = QuaternionConv(channel_num, channel_num, 3, 1, padding=dilation, dilatation=dilation, groups=group, bias=False)\n",
        "        self.norm1 = QuaternionInstanceNorm2d(channel_num)\n",
        "        self.conv2 = QuaternionConv(channel_num, channel_num, 3, 1, padding=dilation, dilatation=dilation, groups=group, bias=False)\n",
        "        self.norm2 = QuaternionInstanceNorm2d(channel_num)\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = F.relu(self.norm1(self.conv1(x)))\n",
        "        y = self.norm2(self.conv2(y))\n",
        "        return F.relu(x+y)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xb2b4XfzBDgS"
      },
      "source": [
        "class GCANet(nn.Module):\n",
        "    def __init__(self, in_c=4, out_c=3, only_residual=True):\n",
        "        super(GCANet, self).__init__()\n",
        "        self.conv1 = QuaternionConv(in_c, 64, 3, 1, 1, 1, bias=False)\n",
        "        self.norm1 = QuaternionInstanceNorm2d(64)\n",
        "        self.conv2 = QuaternionConv(64, 64, 3, 1, 1, 1, bias=False)\n",
        "        self.norm2 = QuaternionInstanceNorm2d(64)\n",
        "        self.conv3 = QuaternionConv(64, 64, 3, 2, 1,1, bias=False)\n",
        "        self.norm3 = QuaternionInstanceNorm2d(64)\n",
        "\n",
        "        self.res1 = SmoothDilatedResidualBlock(64, dilation=2)\n",
        "        self.res2 = SmoothDilatedResidualBlock(64, dilation=2)\n",
        "        self.res3 = SmoothDilatedResidualBlock(64, dilation=2)\n",
        "        self.res4 = SmoothDilatedResidualBlock(64, dilation=4)\n",
        "        self.res5 = SmoothDilatedResidualBlock(64, dilation=4)\n",
        "        self.res6 = SmoothDilatedResidualBlock(64, dilation=4)\n",
        "        self.res7 = ResidualBlock(64, dilation=1)\n",
        "\n",
        "        self.gate = QuaternionConv(64 * 3, 64, 1, 1, 1, bias=True)\n",
        "\n",
        "        self.deconv3 = QuaternionTransposeConv(64, 64, 4, 2, 1, 1)\n",
        "        self.norm4 = QuaternionInstanceNorm2d(64)\n",
        "        self.deconv2 = QuaternionConv(2 * 64, 64, 3, 1, 1, 1)\n",
        "        self.norm5 = QuaternionInstanceNorm2d(64)\n",
        "        self.deconv1 = QuaternionConv(64, out_c, 1, 1, bias=True)\n",
        "        self.only_residual = only_residual\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = F.relu(self.norm1(self.conv1(x)))\n",
        "        y0 = F.relu(self.norm2(self.conv2(y)))\n",
        "        y1 = F.relu(self.norm3(self.conv3(y0)))\n",
        "\n",
        "        y = self.res1(y1)\n",
        "        y = self.res2(y)\n",
        "        y = self.res3(y)\n",
        "        y2 = self.res4(y)\n",
        "        y = self.res5(y2)\n",
        "        y = self.res6(y)\n",
        "        y3 = self.res7(y)\n",
        "\n",
        "\n",
        "        r = torch.cat((get_r(y1), get_r(y2), get_r(y3)), dim=1)\n",
        "        i = torch.cat((get_i(y1), get_i(y2), get_i(y3)), dim=1)\n",
        "        j = torch.cat((get_j(y1), get_j(y2), get_j(y3)), dim=1)\n",
        "        k = torch.cat((get_k(y1), get_k(y2), get_k(y3)), dim=1)\n",
        "\n",
        "        gated_y = self.gate(torch.cat((r, i, j, k), dim=1))\n",
        "\n",
        "        y = F.relu(self.norm4(self.deconv3(gated_y)))   \n",
        "        r = torch.cat((get_r(y0), get_r(y)), dim=1)\n",
        "        i = torch.cat((get_i(y0), get_i(y)), dim=1)\n",
        "        j = torch.cat((get_j(y0), get_j(y)), dim=1)\n",
        "        k = torch.cat((get_k(y0), get_k(y)), dim=1)\n",
        "        y = torch.cat((r, i, j, k), dim=1)     \n",
        "        y = F.relu(self.norm5(self.deconv2(y)))\n",
        "        if self.only_residual:\n",
        "            y = self.deconv1(y)\n",
        "        else:\n",
        "            y = F.relu(self.deconv1(y))\n",
        "\n",
        "        return y"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88T2V8ilKrK"
      },
      "source": [
        "# Perceptual loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__o0aIqclZqA"
      },
      "source": [
        "from torchvision.models import vgg16"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpKENP0vmHP6"
      },
      "source": [
        "class LossNetwork(torch.nn.Module):\n",
        "    def __init__(self, vgg_model):\n",
        "        super(LossNetwork, self).__init__()\n",
        "        self.vgg_layers = vgg_model\n",
        "        self.layer_name_mapping = {\n",
        "            '3': \"relu1_2\",\n",
        "            '8': \"relu2_2\",\n",
        "            '15': \"relu3_3\"\n",
        "        }\n",
        "\n",
        "    def output_features(self, x):\n",
        "        output = {}\n",
        "        for name, module in self.vgg_layers._modules.items():\n",
        "            x = module(x)\n",
        "            if name in self.layer_name_mapping:\n",
        "                output[self.layer_name_mapping[name]] = x\n",
        "        return list(output.values())\n",
        "\n",
        "    def forward(self, dehaze, gt):\n",
        "        loss = []\n",
        "        dehaze_features = self.output_features(dehaze)\n",
        "        gt_features = self.output_features(gt)\n",
        "        for dehaze_feature, gt_feature in zip(dehaze_features, gt_features):\n",
        "            loss.append(F.mse_loss(dehaze_feature, gt_feature))\n",
        "\n",
        "        return sum(loss)/len(loss)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZIBPJrelM8R"
      },
      "source": [
        "# # --- Define the perceptual loss network --- #\n",
        "# vgg_model = vgg16(pretrained=True).features[:16]\n",
        "# vgg_model = vgg_model.cuda()\n",
        "# for param in vgg_model.parameters():\n",
        "#     param.requires_grad = False\n",
        "# loss_network = LossNetwork(vgg_model)\n",
        "# loss_network.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF2TBT9f_ssk"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cePOjqKA6to4"
      },
      "source": [
        "def quat_l2(output, target):\n",
        "    check_input(output)\n",
        "    check_input(target)\n",
        "    r = get_r(output) - get_r(target)\n",
        "    i = get_i(output) - get_i(target)\n",
        "    j = get_j(output) - get_j(target)\n",
        "    k = get_k(output) - get_k(target)\n",
        "    modulus = torch.sqrt(r*r + i*i + j*j + k*k)\n",
        "    loss = torch.mean(modulus)\n",
        "    return loss"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls rain200H/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYbsrQWxvvLY",
        "outputId": "8600259b-cdf4-41f6-b7ae-5df3da254d01"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test  train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MZ_PGO5_uGv",
        "outputId": "d7773e11-850c-4196-ee18-0b694d8ed5d4"
      },
      "source": [
        "opt = {'network': 'GCANet',\n",
        "          'name': 'default_exp',\n",
        "          'gpu_ids': '0',\n",
        "          'epochs': 15, #100,\n",
        "          'lr': 0.001,\n",
        "          'lr_step': 6,\n",
        "          'lr_gamma': 0.1,\n",
        "          'weight_decay': 0.0005,\n",
        "          'checkpoints_dir': 'checkpoint',\n",
        "          'logDir': 'tblogdir',\n",
        "          'resume_dir': '',\n",
        "          'resume_epoch': 0,\n",
        "          'save_epoch': 5,\n",
        "          'save_latest_freq': 5000,\n",
        "          'test_epoch': 5,\n",
        "          'test_max_size': 1080,\n",
        "          'size_unit': 8,\n",
        "          'print_iter': 100,\n",
        "          'input_folder': './rain200H/train/rain',\n",
        "          'gt_folder': './rain200H/train/norain',\n",
        "          'test_input_folder': './rain200H/test/rain',\n",
        "          'test_gt_folder': './rain200H/test/norain',\n",
        "          'num_workers': 4,\n",
        "          'batch_size': 3,\n",
        "          'only_residual': False,\n",
        "          'loss_func': 'l2',\n",
        "          'inc': 4,\n",
        "          'outc': 4,\n",
        "          'force_rgb': 'store_true',\n",
        "          'no_edge':'store_true'}\n",
        "\n",
        "opt['input_folder'] = os.path.expanduser(opt['input_folder'])\n",
        "opt['gt_folder'] = os.path.expanduser(opt['gt_folder'])\n",
        "opt['test_input_folder'] = os.path.expanduser(opt['test_input_folder'])\n",
        "opt['test_gt_folder'] = os.path.expanduser(opt['test_gt_folder'])\n",
        "\n",
        "\n",
        "if not os.path.exists(os.path.join(opt['checkpoints_dir'], opt['name'])):\n",
        "    os.makedirs(os.path.join(opt['checkpoints_dir'], opt['name']))\n",
        "opt['resume_dir'] = opt['resume_dir'] if opt['resume_dir'] != '' else os.path.join(opt['checkpoints_dir'], opt['name'])\n",
        "\n",
        "# visualizer = TFVisualizer(opt)\n",
        "# ### Log out\n",
        "# with open(os.path.realpath(__file__), 'r') as fid:\n",
        "#     visualizer.print_logs(fid.read())\n",
        "\n",
        "# ## print argument\n",
        "# for key, val in vars(opt).items():\n",
        "#     visualizer.print_logs('%s: %s' % (key, val))\n",
        "\n",
        "opt['gpu_ids'] = [int(x) for x in opt['gpu_ids'].split(',')]\n",
        "assert all(0 <= x <= torch.cuda.device_count() for x in opt['gpu_ids']), 'gpu id should ' \\\n",
        "                                                      'be 0~{0}'.format(torch.cuda.device_count())\n",
        "torch.cuda.set_device(opt['gpu_ids'][0])\n",
        "\n",
        "\n",
        "train_dataset = ImagePairPrefixFolder(opt['input_folder'], opt['gt_folder'], size_unit=opt['size_unit'], force_rgb=opt['force_rgb'])\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=opt['batch_size'], shuffle=True,\n",
        "                              collate_fn=var_custom_collate, pin_memory=True,\n",
        "                              num_workers=opt['num_workers'])\n",
        "\n",
        "opt['do_test'] = opt['test_gt_folder'] != ''\n",
        "if opt['do_test']:\n",
        "    test_dataset = ImagePairPrefixFolder(opt['test_input_folder'], \n",
        "                                         opt['test_gt_folder'],\n",
        "                                         max_img_size=opt['test_max_size'], \n",
        "                                         size_unit=opt['size_unit'], \n",
        "                                         force_rgb=opt['force_rgb'])\n",
        "    test_dataloader = DataLoader(test_dataset, \n",
        "                                 batch_size=1, \n",
        "                                 shuffle=False,\n",
        "                                 collate_fn=var_custom_collate, \n",
        "                                 pin_memory=True,\n",
        "                                 num_workers=1)\n",
        "\n",
        "total_inc = opt['inc'] if opt['no_edge'] else opt['inc'] + 1\n",
        "if opt['network'] == 'GCANet':\n",
        "    net = GCANet(in_c=4, out_c=4, only_residual=opt['only_residual'])\n",
        "else:\n",
        "    print('network structure %s not supported' % opt['network'])\n",
        "    raise ValueError\n",
        "\n",
        "loss_crit = quat_l2\n",
        "loss_crit2 = torch.nn.MSELoss()\n",
        "loss_crit3 = torch.nn.L1Loss()\n",
        "pnsr_crit = torch.nn.MSELoss()\n",
        "\n",
        "if len(opt['gpu_ids']) > 0:\n",
        "    net.cuda()\n",
        "    if len(opt['gpu_ids']) > 1:\n",
        "        net = torch.nn.DataParallel(net)\n",
        "    pnsr_crit = pnsr_crit.cuda()\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr=opt['lr'])\n",
        "step_optim_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=opt['lr_step'], gamma=opt['lr_gamma'])\n",
        "loss_avg = MovingAvg(pool_size=50)\n",
        "\n",
        "start_epoch = 0\n",
        "total_iter = 0\n",
        "\n",
        "if os.path.exists(os.path.join(opt['checkpoints_dir'], opt['name'], 'latest.pth')):\n",
        "    print('resuming from latest.pth')\n",
        "    latest_info = torch.load(os.path.join(opt['checkpoints_dir'], opt['name'], 'latest.pth'))\n",
        "    start_epoch = latest_info['epoch']\n",
        "    total_iter = latest_info['total_iter']\n",
        "    if isinstance(net, torch.nn.DataParallel):\n",
        "        net.module.load_state_dict(latest_info['net_state'])\n",
        "    else:\n",
        "        net.load_state_dict(latest_info['net_state'])\n",
        "    optimizer.load_state_dict(latest_info['optim_state'])\n",
        "\n",
        "if opt['resume_epoch'] > 0:\n",
        "    start_epoch = opt['resume_epoch']\n",
        "    total_iter = opt['resume_epoch'] * len(train_dataloader)\n",
        "    resume_path = os.path.join(opt['resume_epoch'], 'net_epoch_%d.pth') % opt['resume_epoch']\n",
        "    print('resume from : %s' % resume_path)\n",
        "    assert os.path.exists(resume_path), 'cannot find the resume model: %s ' % resume_path\n",
        "    if isinstance(net, torch.nn.DataParallel):\n",
        "        net.module.load_state_dict(torch.load(resume_path))\n",
        "    else:\n",
        "        net.load_state_dict(torch.load(resume_path))\n",
        "\n",
        "for epoch in range(start_epoch, opt['epochs']):\n",
        "    #visualizer.print_logs(\"Start to train epoch %d\" % epoch)\n",
        "    print(\"Start to train epoch %d\" % epoch)\n",
        "    net.train()\n",
        "    for iter, data in enumerate(train_dataloader):\n",
        "        total_iter += 1\n",
        "        optimizer.zero_grad()\n",
        "        step_optim_scheduler.step(epoch)\n",
        "\n",
        "        batch_input_img, batch_input_edge,  batch_gt = data\n",
        "        if len(opt['gpu_ids']) > 0:\n",
        "            batch_input_img, batch_input_edge, batch_gt = batch_input_img.cuda(), batch_input_edge.cuda(), batch_gt.cuda()\n",
        "\n",
        "        if opt['no_edge']:\n",
        "            batch_input = batch_input_img\n",
        "        else:\n",
        "            batch_input = torch.cat((batch_input_img, batch_input_edge), dim=1)\n",
        "   \n",
        "        batch_input_v = Variable(batch_input)\n",
        "        if opt['only_residual']:\n",
        "            batch_gt_v = Variable(batch_gt - (batch_input_img+128))\n",
        "        else:\n",
        "            batch_gt_v = Variable(batch_gt)\n",
        "\n",
        "        pred = net(batch_input_v)\n",
        "\n",
        "        rec_loss1 = loss_crit(pred, batch_gt_v)\n",
        "        rec_loss2 = loss_crit2(pred, batch_gt_v)\n",
        "        rec_loss3 = loss_crit3(pred, batch_gt_v)\n",
        "        #perceptual_loss = loss_network(pred[:, 1:, :, :], batch_gt_v[:, 1:, :, :])\n",
        "        loss = (rec_loss1) * 0.33 + (rec_loss2)*0.33 + (rec_loss3)*0.33 #+ 0.04 *perceptual_loss\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        avg_loss = loss_avg.set_curr_val(loss.data)\n",
        "\n",
        "\n",
        "        if iter % opt['print_iter'] == 0:\n",
        "            # visualizer.plot_current_losses(total_iter, { 'loss': loss})\n",
        "            # visualizer.print_logs('%s Step[%d/%d], lr: %f, mv_avg_loss: %f, loss: %f' %\n",
        "            #                         (str(datetime.datetime.now()).split(' ')[1], iter, len(train_dataloader),\n",
        "            #                          step_optim_scheduler.get_lr()[0], avg_loss, loss))\n",
        "            pass\n",
        "\n",
        "        if total_iter % opt['save_latest_freq'] == 0:\n",
        "            latest_info = {'total_iter': total_iter,\n",
        "                           'epoch': epoch,\n",
        "                           'optim_state': optimizer.state_dict()}\n",
        "            if len(opt['gpu_ids']) > 1:\n",
        "                latest_info['net_state'] = net.module.state_dict()\n",
        "            else:\n",
        "                latest_info['net_state'] = net.state_dict()\n",
        "            print('save lastest model.')\n",
        "            torch.save(latest_info, os.path.join(opt['checkpoints_dir'], opt['name'], 'latest.pth'))\n",
        "\n",
        "    if (epoch+1) % opt['save_epoch'] == 0 :\n",
        "        #visualizer.print_logs('saving model for epoch %d' % epoch)\n",
        "        if len(opt['gpu_ids']) > 1:\n",
        "            torch.save(net.module.state_dict(), os.path.join(opt['checkpoints_dir'], opt['name'], 'net_epoch_%d.pth' % (epoch+1)))\n",
        "        else:\n",
        "            torch.save(net.state_dict(), os.path.join(opt['checkpoints_dir'], opt['name'], 'net_epoch_%d.pth' % (epoch + 1)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start to train epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:154: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
            "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdOsu_v7xJzq"
      },
      "source": [
        "NAME = 'derain'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ify41FCDnHhs"
      },
      "source": [
        "def restore_image(fname):\n",
        "  img = Image.open(fname).convert('RGB')\n",
        "  im_w, im_h = img.size\n",
        "  if im_w % 4 != 0 or im_h % 4 != 0:\n",
        "      img = img.resize((int(im_w // 4 * 4), int(im_h // 4 * 4))) \n",
        "  #img = np.array(img).astype('float')\n",
        "\n",
        "  img = np.array(img)\n",
        "  h, w, c = img.shape\n",
        "  #gray = cv2.imread(fname.replace('hazy', 'trans').replace('.jpg','.png'), 0)\n",
        "  #gray = cv2.resize(gray, (w, h))\n",
        "\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  img = np.dstack([gray[:, :, np.newaxis], img])\n",
        "  img = img.astype('float')\n",
        "\n",
        "  img_data = torch.from_numpy(img.transpose((2, 0, 1))).float()\n",
        "  c, w, h = img_data.size()\n",
        "  #edge_data = torch.zeros((1, w, h))\n",
        "  #in_data = torch.cat((img_data, edge_data), dim=0)\n",
        "  #in_data = torch.cat((img_data, edge_data), dim=1).unsqueeze(0) - 128 \n",
        "  in_data = img_data.reshape(1, 4, w, h) - 128\n",
        "  in_data = in_data.cuda()\n",
        "  with torch.no_grad():\n",
        "      pred = net(Variable(in_data))\n",
        "\n",
        "  out_img_data = (pred.data[0].cpu().float()).round().clamp(0, 255)\n",
        "  out_img = out_img_data.numpy().astype(np.uint8).transpose(1, 2, 0)\n",
        "  return out_img[:, :, 1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1NJ6iZHJJpP"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from skimage.metrics import peak_signal_noise_ratio\n",
        "from skimage.metrics import structural_similarity\n",
        "\n",
        "def image_colorfulness(image):\n",
        "\t# split the image into its respective RGB components\n",
        "\t(B, G, R) = cv2.split(image.astype(\"float\"))\n",
        "\t# compute rg = R - G\n",
        "\trg = np.absolute(R - G)\n",
        "\t# compute yb = 0.5 * (R + G) - B\n",
        "\tyb = np.absolute(0.5 * (R + G) - B)\n",
        "\t# compute the mean and standard deviation of both `rg` and `yb`\n",
        "\t(rbMean, rbStd) = (np.mean(rg), np.std(rg))\n",
        "\t(ybMean, ybStd) = (np.mean(yb), np.std(yb))\n",
        "\t# combine the mean and standard deviations\n",
        "\tstdRoot = np.sqrt((rbStd ** 2) + (ybStd ** 2))\n",
        "\tmeanRoot = np.sqrt((rbMean ** 2) + (ybMean ** 2))\n",
        "\t# derive the \"colorfulness\" metric and return it\n",
        "\treturn stdRoot + (0.3 * meanRoot)\n",
        "\n",
        "\n",
        "hazy_dir = './rain200H/test/rain'\n",
        "gt_dir = './rain200H/test/norain'\n",
        "hazy_imgs = [os.path.basename(fn) for fn in glob(os.path.join(hazy_dir, '*.png'))]\n",
        "\n",
        "\n",
        "psnrs = []\n",
        "ssims = []\n",
        "!mkdir /content/drive/MyDrive/processed/{NAME}\n",
        "for name in hazy_imgs:\n",
        "  fname = os.path.basename(name)\n",
        "  image_name = os.path.join(hazy_dir, name)\n",
        "  gt_name = os.path.join(gt_dir, fname)\n",
        "\n",
        "  reconstructed = restore_image(image_name)\n",
        "  height, width = reconstructed.shape[:2]\n",
        "  gt = cv2.imread(gt_name)\n",
        "  gt = cv2.resize(gt, (width, height))\n",
        "  gt = cv2.cvtColor(gt, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  bgr = cv2.cvtColor(reconstructed, cv2.COLOR_RGB2BGR)\n",
        "  cv2.imwrite(os.path.join('/content/drive/MyDrive/processed/{}'.format(NAME), name.replace('.jpg', '.png')), bgr)\n",
        "  psnrs.append(peak_signal_noise_ratio(gt, reconstructed))\n",
        "\n",
        "  img1 = cv2.cvtColor(reconstructed, cv2.COLOR_RGB2GRAY)\n",
        "  img2 = cv2.cvtColor(gt, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "  ssims.append(structural_similarity(img2, img1))\n",
        "\n",
        "print('ssim:', sum(ssims)/len(ssims))\n",
        "print('psnr:', sum(psnrs)/len(psnrs))\n",
        "\n",
        "!mkdir /content/drive/MyDrive/networks/{NAME}\n",
        "!cp -r checkpoint /content/drive/MyDrive/networks/{NAME}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6afpd_NcYBt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}